{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10章　特徴量選択による次元削減 \n",
    "## レシピ10.1　数値特徴量の分散による閾値処理 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# テスト用のデータをロード\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# 特徴量とターゲットを作成\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# 閾値を作成\n",
    "thresholder = VarianceThreshold(threshold=.5)\n",
    "\n",
    "# 分散の大きい特徴量行列を作成\n",
    "features_high_variance = thresholder.fit_transform(features)\n",
    "\n",
    "# 分散の大きい特徴量行列を表示\n",
    "features_high_variance[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分散を表示\n",
    "thresholder.fit(features).variances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 特徴量行列を標準化\n",
    "scaler = StandardScaler()\n",
    "features_std = scaler.fit_transform(features)\n",
    "\n",
    "# それぞれの特徴量を算出\n",
    "selector = VarianceThreshold()\n",
    "selector.fit(features_std).variances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ10.2　2値特徴量の分散閾値処理 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# 特徴量行列を下記のように作成:\n",
    "# 特徴量 0: 80% クラス 0\n",
    "# 特徴量 1: 80% クラス 1\n",
    "# 特徴量 2: 60% クラス 0, 40% クラス 1\n",
    "features = [[0, 1, 0],\n",
    "            [0, 1, 1],\n",
    "            [0, 1, 0],\n",
    "            [0, 1, 1],\n",
    "            [1, 0, 0]]\n",
    "\n",
    "# 分散で閾値処理\n",
    "thresholder = VarianceThreshold(threshold=(.75 * (1 - .75)))\n",
    "thresholder.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ10.3　強く相関した特徴量の取り扱い \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 2つの特徴量が強く相関した特徴量行列を作成\n",
    "features = np.array([[1, 1, 1],\n",
    "                     [2, 2, 0],\n",
    "                     [3, 3, 1],\n",
    "                     [4, 4, 0],\n",
    "                     [5, 5, 1],\n",
    "                     [6, 6, 0],\n",
    "                     [7, 7, 1],\n",
    "                     [8, 7, 0],\n",
    "                     [9, 7, 1]])\n",
    "\n",
    "# 特徴量行列をDataFrameに変換\n",
    "dataframe = pd.DataFrame(features)\n",
    "\n",
    "# 相関行列を作成\n",
    "corr_matrix = dataframe.corr().abs()\n",
    "\n",
    "# 相関行列の上三角を選択\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# 相関が0.95以上になる特徴量列のインデックスを抽出\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "# 特徴量を削除\n",
    "dataframe.drop(dataframe.columns[to_drop], axis=1).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相関行列を表示\n",
    "dataframe.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相関行列の上三角行列を表示\n",
    "upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ10.4　クラス分類に無関係な特徴量の削除 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "\n",
    "# データをロード\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# データを整数に変換して、カテゴリデータとして扱う\n",
    "features = features.astype(int)\n",
    "\n",
    "# カイ二乗統計量が最大の2つの特徴量を選択\n",
    "chi2_selector = SelectKBest(chi2, k=2)\n",
    "features_kbest = chi2_selector.fit_transform(features, target)\n",
    "\n",
    "# 結果を表示\n",
    "print(\"もとの特徴量数:\", features.shape[1])\n",
    "print(\"削減後の特徴量数:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最も高いF値を持つ特徴量を2つ選択\n",
    "fvalue_selector = SelectKBest(f_classif, k=2)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "\n",
    "# 結果を表示\n",
    "print(\"もとの特徴量数:\", features.shape[1])\n",
    "print(\"削減後の特徴量数:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "# F値が上位75パーセントの特徴量を選択\n",
    "fvalue_selector = SelectPercentile(f_classif, percentile=75)\n",
    "features_kbest = fvalue_selector.fit_transform(features, target)\n",
    "\n",
    "# 結果を表示\n",
    "print(\"もとの特徴量数:\", features.shape[1])\n",
    "print(\"削減後の特徴量数:\", features_kbest.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ10.5　再帰的な特徴量の除去 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import warnings\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "# わずらわしいが無害な警告を抑止\n",
    "warnings.filterwarnings(action=\"ignore\", module=\"scipy\",\n",
    "message=\"^internal gelsd\")\n",
    "\n",
    "# 特徴量行列、ターゲットベクトル、真の相関係数を作成\n",
    "features, target = make_regression(n_samples = 10000,\n",
    "                                   n_features = 100,\n",
    "                                   n_informative = 2,\n",
    "                                   random_state = 1)\n",
    "\n",
    "# 線形回帰器を作成\n",
    "ols = linear_model.LinearRegression()\n",
    "\n",
    "# 再帰的に特徴量を除去\n",
    "rfecv = RFECV(estimator=ols, step=1, scoring=\"neg_mean_squared_error\")\n",
    "rfecv.fit(features, target)\n",
    "rfecv.transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 維持すべき特徴量の数\n",
    "rfecv.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 維持すべき特徴量を表示\n",
    "rfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量のランクを表示（最良が1）\n",
    "rfecv.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
