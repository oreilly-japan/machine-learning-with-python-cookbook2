{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8章　画像の取り扱い \n",
    "## レシピ8.1　画像のロード "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 画像をグレースケール（モノクロ）として読み込み\n",
    "image = cv2.imread(\"images/plane.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ型を表示\n",
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データを表示\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの形状を表示\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初のピクセルを表示\n",
    "image[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カラーで画像を読み込み\n",
    "image_bgr = cv2.imread(\"images/plane.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# ピクセルを表示\n",
    "image_bgr[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGBに変換\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_rgb), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.2　画像の保存 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# モノクロで画像を読み込み\n",
    "image = cv2.imread(\"images/plane.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 画像を保存\n",
    "cv2.imwrite(\"images/plane_new.jpg\", image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.3　画像サイズの変更 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# モノクロで画像を読み込み\n",
    "image = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 画像を50×50ピクセルにサイズ変更\n",
    "image_50x50 = cv2.resize(image, (50, 50))\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_50x50, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.4　画像のクロップ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# モノクロで画像を読み込み\n",
    "image = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 列の最初の半分を選択。行はすべての行を使う\n",
    "image_cropped = image[:,:128]\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_cropped, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.5　画像のぼかし \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# モノクロで画像を読み込み\n",
    "image = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 画像をぼかす\n",
    "image_blurry = cv2.blur(image, (5,5))\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_blurry, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像をぼかす\n",
    "image_very_blurry = cv2.blur(image, (100,100))\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_very_blurry, cmap=\"gray\"), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カーネルを作成\n",
    "kernel = np.ones((5,5)) / 25.0\n",
    "\n",
    "# カーネルを表示\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カーネルを適用\n",
    "image_kernel = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_kernel, cmap=\"gray\"), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.6　画像をくっきりさせる \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# モノクロで画像を読み込み\n",
    "image = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# カーネルの作成\n",
    "kernel = np.array([[0, -1, 0],\n",
    "[-1, 5,-1],\n",
    "[0, -1, 0]])\n",
    "\n",
    "# 画像をくっきりさせる\n",
    "image_sharp = cv2.filter2D(image, -1, kernel)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_sharp, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.7　コントラストの強調 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# モノクロで画像を読み込み\n",
    "image = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 画像を強調\n",
    "image_enhanced = cv2.equalizeHist(image)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_enhanced, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像をロード\n",
    "image_bgr = cv2.imread(\"images/plane.jpg\")\n",
    "\n",
    "# YUVに変換\n",
    "image_yuv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "# ヒストグラム均等化を適用\n",
    "image_yuv[:, :, 0] = cv2.equalizeHist(image_yuv[:, :, 0])\n",
    "\n",
    "# RGBに変換\n",
    "image_rgb = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2RGB)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_rgb), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.8　色の分離 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 画像をロード\n",
    "image_bgr = cv2.imread('images/plane_256x256.jpg')\n",
    "\n",
    "# BGR色空間からHSV色空間に変換\n",
    "image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# HSV空間で「青」の範囲を定義\n",
    "lower_blue = np.array([50,100,50])\n",
    "upper_blue = np.array([130,255,255])\n",
    "\n",
    "# マスクを作成\n",
    "mask = cv2.inRange(image_hsv, lower_blue, upper_blue)\n",
    "\n",
    "# 画像にマスクを適用\n",
    "image_bgr_masked = cv2.bitwise_and(image_bgr, image_bgr, mask=mask)\n",
    "\n",
    "# BGR色空間からRGB色空間に変換\n",
    "image_rgb = cv2.cvtColor(image_bgr_masked, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_rgb), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マスク画像を表示\n",
    "plt.imshow(mask, cmap='gray'), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.9　画像の2値化 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# モノクロで画像を読み込み\n",
    "image_grey = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 適応的閾値処理を実行\n",
    "max_output_value = 255\n",
    "neighborhood_size = 99\n",
    "subtract_from_mean = 10\n",
    "image_binarized = cv2.adaptiveThreshold(image_grey,\n",
    "                                        max_output_value,\n",
    "                                        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                        cv2.THRESH_BINARY,\n",
    "                                        neighborhood_size,\n",
    "                                        subtract_from_mean)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_binarized, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.ADAPTIVE_THRESH_MEAN_Cを使用\n",
    "image_mean_threshold = cv2.adaptiveThreshold(image_grey,\n",
    "                                             max_output_value,\n",
    "                                             cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                             cv2.THRESH_BINARY,\n",
    "                                             neighborhood_size,\n",
    "                                             subtract_from_mean)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_mean_threshold, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.10　背景除去 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 画像をロードしてRGBに変換\n",
    "image_bgr = cv2.imread('images/plane_256x256.jpg')\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 矩形：始点x、始点y、幅、高さ\n",
    "rectangle = (0, 56, 256, 150)\n",
    "\n",
    "# マスクの初期値を作成\n",
    "mask = np.zeros(image_rgb.shape[:2], np.uint8)\n",
    "\n",
    "# grabCutで用いる一時配列を作成\n",
    "bgdModel = np.zeros((1, 65), np.float64)\n",
    "fgdModel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "# grabCutを実行\n",
    "cv2.grabCut(image_rgb, # 入力画像\n",
    "            mask,      # マスク\n",
    "            rectangle, # 範囲指定の矩形\n",
    "            bgdModel,  # 背景のための一時配列\n",
    "            fgdModel,  # 前景のための一時配列\n",
    "            5,         # 繰り返し回数\n",
    "            cv2.GC_INIT_WITH_RECT) # 矩形を用いて初期化\n",
    "\n",
    "# マスクを作成。背景であることが確実もしくは高確率な場所を0に、それ以外を1に\n",
    "mask_2 = np.where((mask==2) | (mask==0), 0, 1).astype('uint8')\n",
    "\n",
    "# 画像とマスクを掛け合わせて背景を除去\n",
    "image_rgb_nobg = image_rgb * mask_2[:, :, np.newaxis]\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_rgb_nobg), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マスクを表示\n",
    "plt.imshow(mask, cmap='gray'), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# マスクを表示\n",
    "plt.imshow(mask_2, cmap='gray'), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.11　エッジの検出 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# モノクロで画像を読み込み\n",
    "image_gray = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 輝度の中央値を計算\n",
    "median_intensity = np.median(image_gray)\n",
    "\n",
    "# 中央値0.67倍と1.33倍を閾値として設定\n",
    "lower_threshold = int(max(0, (1.0 - 0.33) * median_intensity))\n",
    "upper_threshold = int(min(255, (1.0 + 0.33) * median_intensity))\n",
    "\n",
    "# Cannyエッジ検出を適用\n",
    "image_canny = cv2.Canny(image_gray, lower_threshold, upper_threshold)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_canny, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.12　コーナーの検出 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# モノクロで画像を読み込み\n",
    "image_bgr = cv2.imread(\"images/plane_256x256.jpg\")\n",
    "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "image_gray = np.float32(image_gray)\n",
    "\n",
    "# コーナー検出のパラメータを設定\n",
    "block_size = 2\n",
    "aperture = 29\n",
    "free_parameter = 0.04\n",
    "\n",
    "# コーナー検出\n",
    "detector_responses = cv2.cornerHarris(image_gray,\n",
    "                                      block_size,\n",
    "                                      aperture,\n",
    "                                      free_parameter)\n",
    "\n",
    "# コーナー部分を強調\n",
    "detector_responses = cv2.dilate(detector_responses, None)\n",
    "\n",
    "# 検出器の反応が閾値以上に大きい場所だけを保持して、白くする\n",
    "threshold = 0.02\n",
    "image_bgr[detector_responses >\n",
    "          threshold *\n",
    "          detector_responses.max()] = [255,255,255]\n",
    "\n",
    "# モノクロに変換\n",
    "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_gray, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コーナーの候補を表示\n",
    "plt.imshow(detector_responses, cmap='gray'), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像をロード\n",
    "image_bgr = cv2.imread('images/plane_256x256.jpg')\n",
    "image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 検出したいコーナーの数\n",
    "corners_to_detect = 10\n",
    "minimum_quality_score = 0.05\n",
    "minimum_distance = 25\n",
    "\n",
    "# コーナーを検出\n",
    "corners = cv2.goodFeaturesToTrack(image_gray,\n",
    "                                  corners_to_detect,\n",
    "                                  minimum_quality_score,\n",
    "                                  minimum_distance)\n",
    "corners = np.int16(corners)\n",
    "\n",
    "# 各コーナーに白い円を描画\n",
    "for corner in corners:\n",
    "    x, y = corner[0]\n",
    "    cv2.circle(image_bgr, (x,y), 10, (255,255,255), -1)\n",
    "\n",
    "# モノクロで画像を読み込み\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 画像を表示\n",
    "plt.imshow(image_rgb, cmap='gray'), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.13　機械学習用の特徴量を作成 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# モノクロで画像読み込み\n",
    "image = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 10×10ピクセルにサイズ変換\n",
    "image_10x10 = cv2.resize(image, (10, 10))\n",
    "\n",
    "# 1次元ベクトルに変換\n",
    "image_10x10.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_10x10, cmap=\"gray\"), plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_10x10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_10x10.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カラーで画像をロード\n",
    "image_color = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# 10×10ピクセルにサイズ変換\n",
    "image_color_10x10 = cv2.resize(image_color, (10, 10))\n",
    "\n",
    "# 1次元のベクトルに変換して、形を表示\n",
    "image_color_10x10.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モノクロで画像を読み込み\n",
    "image_256x256_gray = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# 1次元のベクトルに変換して、形を表示\n",
    "image_256x256_gray.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カラーで画像をロード\n",
    "image_256x256_color = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# 1次元のベクトルに変換して、形を表示\n",
    "image_256x256_color.flatten().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.14　色ヒストグラムをエンコードした特徴量 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# 画像をロード\n",
    "image_bgr = cv2.imread(\"images/plane_256x256.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# RGBに変換\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 特徴量値を格納するリストを作成\n",
    "features = []\n",
    "\n",
    "# それぞれの色チャネルに対してヒストグラムを計算\n",
    "colors = (\"r\",\"g\",\"b\")\n",
    "\n",
    "# それぞれの色チャネルに対してヒストグラムを計算して特徴量値のリストに追加\n",
    "for i, channel in enumerate(colors):\n",
    "    histogram = cv2.calcHist([image_rgb], # 画像\n",
    "                             [i],         # チャネルのインデックス\n",
    "                             None,        # マスクは用いない\n",
    "                             [256],       # ヒストグラムの大きさ\n",
    "                             [0,256])     # 範囲\n",
    "    features.extend(histogram)\n",
    "\n",
    "# 観測値の特徴量値となるベクトルを作成\n",
    "observation = np.array(features).flatten()\n",
    "\n",
    "# 観測値の最初の5つの特徴量を表示\n",
    "observation[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGBチャネル値を表示\n",
    "image_rgb[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasをインポート\n",
    "import pandas as pd\n",
    "\n",
    "# データを作成\n",
    "data = pd.Series([1, 1, 2, 2, 3, 3, 3, 4, 5])\n",
    "\n",
    "# ヒストグラムを表示\n",
    "data.hist(grid=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# それぞれの色チャネルに対してヒストグラムを計算\n",
    "colors = (\"r\",\"g\",\"b\")\n",
    "\n",
    "# それぞれの色チャネルに対して：ヒストグラムを計算してプロット\n",
    "for i, channel in enumerate(colors):\n",
    "    histogram = cv2.calcHist([image_rgb], # 画像\n",
    "                             [i],         # チャネルのインデックス\n",
    "                             None,        # マスクは用いない\n",
    "                             [256],       # ヒストグラムの大きさ\n",
    "                             [0,256])     # 範囲\n",
    "    plt.plot(histogram, color = channel)\n",
    "    plt.xlim([0,256])\n",
    "\n",
    "# プロットしたものを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.15　訓練済みのエンベディングを特徴量として用いる \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# 画像をロード\n",
    "image_bgr = cv2.imread(\"images/plane.jpg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# PyTorchのデータ型に変換\n",
    "convert_tensor = transforms.ToTensor()\n",
    "pytorch_image = convert_tensor(np.array(image_rgb))\n",
    "\n",
    "# 訓練済みモデルをロード\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# 出力として使いたいモデルの層を選択\n",
    "layer = model._modules.get('avgpool')\n",
    "\n",
    "# モデルを評価モードに\n",
    "model.eval()\n",
    "\n",
    "# no_gradオプションを付けてエンベディングを計算\n",
    "with torch.no_grad():\n",
    "    embedding = model(pytorch_image.unsqueeze(0))\n",
    "    \n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# 画像をロード\n",
    "image_bgr = cv2.imread(\"images/plane.jpg\", cv2.IMREAD_COLOR)\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# TensorFlowのデータ型に変換\n",
    "tf_image = tf.image.convert_image_dtype([image_rgb], tf.float32)\n",
    "\n",
    "# Inception V1を用いてモデルを作り、エンベディングを取得\n",
    "embedding_model = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/imagenet/inception_v1/feature_vector/5\"\n",
    ")\n",
    "embeddings = embedding_model(tf_image)\n",
    "\n",
    "# エンベディングの形状を表示\n",
    "print(embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ8.16　OpenCVを用いたオブジェクトの検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 先に下記を実行\n",
    "# mkdir models && cd models\n",
    "# wget -O haarcascade_frontalface_default.xml https://tinyurl.com/mrc6jwhp\n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "face_cascade.load(\n",
    "    cv2.samples.findFile(\n",
    "        \"models/haarcascade_frontalface_default.xml\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 画像をロード\n",
    "image_bgr = cv2.imread(\"images/kyle_pic.jpg\", cv2.IMREAD_COLOR)\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# 顔画像を検出して矩形を描画\n",
    "faces = face_cascade.detectMultiScale(image_rgb)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image_rgb, (x, y),\n",
    "                  (x + h, y + w),\n",
    "                  (0, 255, 0), 5)\n",
    "\n",
    "# 画像を表示\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.imshow(image_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "## レシピ8.17　PyTorchを用いた画像のクラス分類 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "import urllib.request\n",
    "\n",
    "# Imagenetのクラスを取得\n",
    "with urllib.request.urlopen(\n",
    "    \"https://raw.githubusercontent.com/raghakot/keras-vis/master/resources/imagenet_class_index.json\"\n",
    "    ) as url:\n",
    "    imagenet_class_index = json.load(url)\n",
    "\n",
    "# 訓練済みモデルを作成\n",
    "model = resnet18(pretrained=True)\n",
    "\n",
    "# 画像をロード\n",
    "image_bgr = cv2.imread(\"images/plane.jpg\", cv2.IMREAD_COLOR)\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# PyTorchのデータ型に変換\n",
    "convert_tensor = transforms.ToTensor()\n",
    "pytorch_image = convert_tensor(np.array(image_rgb))\n",
    "\n",
    "# モデルを評価モードに設定\n",
    "model.eval()\n",
    "\n",
    "# 予測を実行\n",
    "prediction = model(pytorch_image.unsqueeze(0))\n",
    "\n",
    "# 最も予測確率の高いインデックスを取得\n",
    "_, index = torch.max(prediction, 1)\n",
    "\n",
    "# 確率をパーセンテージに変換\n",
    "percentage = torch.nn.functional.softmax(prediction, dim=1)[0] * 100\n",
    "\n",
    "# インデックスに該当するアイテム名と確信度を表示\n",
    "print(imagenet_class_index[str(index.tolist()[0])][1],\n",
    "      percentage[index.tolist()[0]].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
