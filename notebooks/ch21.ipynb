{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21章　ニューラルネットワーク "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.1　PyTorchの自動微分を使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "\n",
    "# 勾配を必要とするPyTorchのテンソルを作成\n",
    "t = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "\n",
    "# 順伝搬を模擬したテンソル演算を実行\n",
    "tensor_sum = t.sum()\n",
    "\n",
    "# 逆伝搬を実行\n",
    "tensor_sum.backward()\n",
    "\n",
    "# 勾配を表示\n",
    "t.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1.0,2.0,3.0], requires_grad=True)\n",
    "tensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.2　ニューラルネットワークのためのデータ前処理 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# 特徴量を作成\n",
    "features = np.array([[-100.1, 3240.1],\n",
    "                     [-200.2, -234.1],\n",
    "                     [5000.5, 150.1],\n",
    "                     [6000.6, -125.1],\n",
    "                     [9000.9, -673.1]])\n",
    "\n",
    "# 標準化器を作成\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# 特徴量を標準化\n",
    "features_standardized = scaler.fit_transform(features)\n",
    "\n",
    "# テンソルに変換\n",
    "features_standardized_tensor = torch.from_numpy(features_standardized)\n",
    "\n",
    "# 特徴量を表示\n",
    "features_standardized_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "\n",
    "# 特徴量を作成\n",
    "torch_features = torch.tensor([[-100.1, 3240.1],\n",
    "                               [-200.2, -234.1],\n",
    "                               [5000.5, 150.1],\n",
    "                               [6000.6, -125.1],\n",
    "                               [9000.9, -673.1]], requires_grad=True)\n",
    "\n",
    "# 平均値と標準偏差を算出\n",
    "mean = torch_features.mean(0, keepdim=True)\n",
    "standard_deviation = torch_features.std(0, unbiased=False, keepdim=True)\n",
    "\n",
    "# 平均値と標準偏差を用いて特徴量を標準化\n",
    "torch_features_standardized = torch_features - mean\n",
    "torch_features_standardized /= standard_deviation\n",
    "\n",
    "# 標準化された特徴量を表示\n",
    "torch_features_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.3　ニューラルネットワークの設計 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 16)\n",
    "        self.fc2 = nn.Linear(16, 16)\n",
    "        self.fc3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# ニューラルネットワークを初期化\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# ロス関数と最適化器を定義\n",
    "loss_criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.RMSprop(network.parameters())\n",
    "\n",
    "# ネットワークを表示\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# ネットワークを作成し表示\n",
    "SimpleNeuralNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.4　2クラス分類器の訓練 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練セットとテストセットを作成\n",
    "features, target = make_classification(n_classes=2, n_features=10, n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 乱数シードを設定\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# データをPyTorchのテンソルに変換\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# ニューラルネットワークを初期化\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# ロス関数と最適化器を定義\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# データローダを定義\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# torch 2.0の最適化器を用いてモデルをコンパイル\n",
    "network = torch.compile(network)\n",
    "\n",
    "# ニューラルネットワークを訓練\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch:\", epoch+1, \"\\tLoss:\", loss.item())\n",
    "\n",
    "# ニューラルネットワークを評価\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = criterion(output, y_test)\n",
    "    test_accuracy = (output.round() == y_test).float().mean()\n",
    "    print(\"Test Loss:\", test_loss.item(), \"\\tTest Accuracy:\", test_accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.5　多クラス分類器の訓練 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "N_CLASSES = 3\n",
    "EPOCHS = 3\n",
    "\n",
    "# 訓練セットとテストセットを作成\n",
    "features, target = make_classification(n_classes=N_CLASSES, n_informative=9,\n",
    "    n_redundant=0, n_features=10, n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 乱数シードを設定\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# データをPyTorchのテンソルに変換\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.nn.functional.one_hot(torch.from_numpy(target_train).long(),\n",
    "    num_classes=N_CLASSES).float()\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.nn.functional.one_hot(torch.from_numpy(target_test).long(),\n",
    "    num_classes=N_CLASSES).float()\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,3),\n",
    "            torch.nn.Softmax()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# ニューラルネットワークを初期化\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# ロス関数と最適化器を定義\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# データローダを定義\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# torch 2.0の最適化器を用いてモデルをコンパイル\n",
    "network = torch.compile(network)\n",
    "\n",
    "# ニューラルネットワークを訓練\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch:\", epoch+1, \"\\tLoss:\", loss.item())\n",
    "\n",
    "# ニューラルネットワークを評価\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = criterion(output, y_test)\n",
    "    test_accuracy = (output.round() == y_test).float().mean()\n",
    "    print(\"Test Loss:\", test_loss.item(), \"\\tTest Accuracy:\", test_accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ターゲット行列を表示\n",
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.6　回帰器を訓練する \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "# 訓練セットとテストセットを作成\n",
    "features, target = make_regression(n_features=10, n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 乱数シードを設定\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# データをPyTorchのテンソルに変換\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1,1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1,1)\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,1),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "    \n",
    "# ニューラルネットワークを初期化\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# ロス関数と最適化器を定義\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# データローダを定義\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# torch 2.0の最適化器を用いてモデルをコンパイル\n",
    "network = torch.compile(network)\n",
    "\n",
    "# ニューラルネットワークを訓練\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch:\", epoch+1, \"\\tLoss:\", loss.item())\n",
    "\n",
    "# ニューラルネットワークを評価\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = float(criterion(output, y_test))\n",
    "    print(\"Test MSE:\", test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.7　予測を行う \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練セットとテストセットを作成\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 乱数シードを設定\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# データをPyTorchのテンソルに変換\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# ニューラルネットワークを初期化\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# ロス関数と最適化器を定義\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# データローダを定義\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# torch 2.0の最適化器を用いてモデルをコンパイル\n",
    "network = torch.compile(network)\n",
    "\n",
    "# ニューラルネットワークを訓練\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch:\", epoch+1, \"\\tLoss:\", loss.item())\n",
    "\n",
    "# ニューラルネットワークを評価\n",
    "with torch.no_grad():\n",
    "    predicted_class = network.forward(x_train).round()\n",
    "\n",
    "predicted_class[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.8　訓練過程の可視化 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 訓練セットとテストセットを作成\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 乱数シードを設定\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# データをPyTorchのテンソルに変換\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# ニューラルネットワークを初期化\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# ロス関数と最適化器を定義\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# データローダを定義\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# torch 2.0の最適化器を用いてモデルをコンパイル\n",
    "network = torch.compile(network)\n",
    "\n",
    "# ニューラルネットワークを訓練\n",
    "epochs = 8\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_output = network(x_train)\n",
    "        train_loss = criterion(output, target)\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "        test_output = network(x_test)\n",
    "        test_loss = criterion(test_output, y_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "# ロスの履歴を可視化\n",
    "epochs = range(0, epochs)\n",
    "plt.plot(epochs, train_losses, \"r--\")\n",
    "plt.plot(epochs, test_losses, \"b-\")\n",
    "plt.legend([\"Training Loss\", \"Test Loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.9　重みの正則化による過学習の緩和 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練セットとテストセットを作成\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 乱数シードを設定\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# データをPyTorchのテンソルに変換\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# ニューラルネットワークを初期化\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# ロス関数と最適化器を定義\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "# データローダを定義\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# torch 2.0の最適化器を用いてモデルをコンパイル\n",
    "network = torch.compile(network)\n",
    "\n",
    "# ニューラルネットワークを訓練\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# ニューラルネットワークを評価\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = criterion(output, y_test)\n",
    "    test_accuracy = (output.round() == y_test).float().mean()\n",
    "    print(\"Test Loss:\", test_loss.item(), \"\\tTest Accuracy:\",\n",
    "        test_accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.10　早期停止による過学習の緩和 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "import lightning as pl\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練セットとテストセットを作成\n",
    "features, target = make_classification(n_classes=2, n_features=10, n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 乱数シードを設定\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# データをPyTorchのテンソルに変換\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "class LightningNetwork(pl.LightningModule):\n",
    "    def __init__(self, network):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.metric = nn.functional.binary_cross_entropy\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # このtraining_stepが訓練ループを定義している\n",
    "        data, target = batch\n",
    "        output = self.network(data)\n",
    "        loss = self.criterion(output, target)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "# データローダを定義\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# ニューラルネットワークを初期化\n",
    "network = LightningNetwork(SimpleNeuralNet())\n",
    "\n",
    "# ニューラルネットワークを訓練\n",
    "trainer = pl.Trainer(callbacks=[EarlyStopping(monitor=\"val_loss\", mode=\"min\",\n",
    "    patience=3)], max_epochs=1000)\n",
    "trainer.fit(model=network, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークを訓練\n",
    "trainer = pl.Trainer(max_epochs=1000)\n",
    "trainer.fit(model=network, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.11　ドロップアウトによる過学習の緩和 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練セットとテストセットを作成\n",
    "features, target = make_classification(n_classes=2, n_features=10, n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 乱数シードを設定\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# データをPyTorchのテンソルに変換\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Dropout(0.1), # ニューロンの10%をドロップ\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# ニューラルネットワークを初期化\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# ロス関数と最適化器を定義\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# データローダを定義\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# torch 2.0の最適化器を用いてモデルをコンパイル\n",
    "network = torch.compile(network)\n",
    "\n",
    "# ニューラルネットワークを訓練\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch:\", epoch+1, \"\\tLoss:\", loss.item())\n",
    "\n",
    "# ニューラルネットワークを評価\n",
    "with torch.no_grad():\n",
    "    output = network(x_test)\n",
    "    test_loss = criterion(output, y_test)\n",
    "    test_accuracy = (output.round() == y_test).float().mean()\n",
    "    print(\"Test Loss:\", test_loss.item(), \"\\tTest Accuracy:\", test_accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.12　モデル訓練の途中結果をセーブする \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練セットとテストセットを作成\n",
    "features, target = make_classification(n_classes=2, n_features=10, n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 乱数シードを設定\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# データをPyTorchのテンソルに変換\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Dropout(0.1), # ニューロンの10%をドロップ\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# ニューラルネットワークを初期化\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# ロス関数と最適化器を定義\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# データローダを定義\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# torch 2.0の最適化器を用いてモデルをコンパイル\n",
    "network = torch.compile(network)\n",
    "\n",
    "# ニューラルネットワークを訓練\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 各エポック終了後にモデルをセーブ\n",
    "        torch.save(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': network.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            },\n",
    "            \"model.pt\"\n",
    "        )\n",
    "    print(\"Epoch:\", epoch+1, \"\\tLoss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.13　ニューラルネットワークのチューニング \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import RMSprop\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "from ray import tune, train\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練セットとテストセットを作成\n",
    "features, target = make_classification(n_classes=2, n_features=10, n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 乱数シードを設定\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# データをPyTorchのテンソルに変換\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self, layer_size_1=10, layer_size_2=10):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, layer_size_1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(layer_size_1, layer_size_2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(layer_size_2, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "config = {\n",
    "    \"layer_size_1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "    \"layer_size_2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "    \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "}\n",
    "\n",
    "scheduler = ASHAScheduler(\n",
    "    metric=\"loss\",\n",
    "    mode=\"min\",\n",
    "    max_t=1000,\n",
    "    grace_period=1,\n",
    "    reduction_factor=2\n",
    ")\n",
    "\n",
    "reporter = CLIReporter(\n",
    "    parameter_columns=[\"layer_size_1\", \"layer_size_2\", \"lr\"],\n",
    "    metric_columns=[\"loss\"]\n",
    ")\n",
    "\n",
    "# ニューラルネットワークを訓練\n",
    "def train_model(config, epochs=3):\n",
    "    network = SimpleNeuralNet(config[\"layer_size_1\"], config[\"layer_size_2\"])\n",
    "\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(network.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "    \n",
    "    train_data = TensorDataset(x_train, y_train)\n",
    "    train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "    # torch 2.0の最適化器を用いてモデルをコンパイル\n",
    "    network = torch.compile(network)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = network(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train.report({\"loss\":loss.item()})\n",
    "\n",
    "result = tune.run(\n",
    "    train_model,\n",
    "    resources_per_trial={\"cpu\": 2},\n",
    "    config=config,\n",
    "    num_samples=1,\n",
    "    scheduler=scheduler,\n",
    "    progress_reporter=reporter\n",
    ")\n",
    "\n",
    "best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial final validation loss: {}\".format(\n",
    "    best_trial.last_result[\"loss\"]))\n",
    "\n",
    "best_trained_model = SimpleNeuralNet(best_trial.config[\"layer_size_1\"],\n",
    "    best_trial.config[\"layer_size_2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## レシピ21.14　ニューラルネットワークを可視化する "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリをロード\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import RMSprop\n",
    "from torchviz import make_dot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 訓練セットとテストセットを作成\n",
    "features, target = make_classification(n_classes=2, n_features=10,\n",
    "    n_samples=1000)\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.1, random_state=1)\n",
    "\n",
    "# 乱数シードを設定\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# データをPyTorchのテンソルに変換\n",
    "x_train = torch.from_numpy(features_train).float()\n",
    "y_train = torch.from_numpy(target_train).float().view(-1, 1)\n",
    "x_test = torch.from_numpy(features_test).float()\n",
    "y_test = torch.from_numpy(target_test).float().view(-1, 1)\n",
    "\n",
    "# `Sequential`を用いてニューラルネットワークを定義\n",
    "class SimpleNeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNeuralNet, self).__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(10, 16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16,16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(16, 1),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        return x\n",
    "\n",
    "# ニューラルネットワークを初期化\n",
    "network = SimpleNeuralNet()\n",
    "\n",
    "# ロス関数と最適化器を定義\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = RMSprop(network.parameters())\n",
    "\n",
    "# データローダを定義\n",
    "train_data = TensorDataset(x_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "# torch 2.0の最適化器を用いてモデルをコンパイル\n",
    "#network = torch.compile(network)\n",
    "\n",
    "# ニューラルネットワークを訓練\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "make_dot(output, params=dict(\n",
    "    list(\n",
    "        network.named_parameters()\n",
    "        )\n",
    "      )   \n",
    "    ).render(\n",
    "        \"simple_neural_network\",\n",
    "        format=\"png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
